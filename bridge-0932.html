<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Voice Chat</title>
  <style>
    :root{color-scheme:light dark;font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif}
    body{margin:0;background:#0f1115;color:#e5e7eb;display:flex;min-height:100vh;align-items:center;justify-content:center}
    #app{width:min(720px,92vw);background:#151922;border-radius:16px;padding:20px 20px 16px;box-shadow:0 10px 30px rgba(0,0,0,.35)}
    h1{margin:0 0 12px;font-size:22px}
    #status{display:flex;align-items:center;gap:8px;margin-bottom:12px;font-weight:600}
    #indicator{font-size:18px}
    #chat{height:300px;overflow:auto;background:#0b0e14;border-radius:12px;padding:12px;display:flex;flex-direction:column;gap:10px}
    .msg{padding:8px 10px;border-radius:10px;line-height:1.35;white-space:pre-wrap}
    .msg.user{background:#1f2937;align-self:flex-end}
    .msg.assistant{background:#0f172a;align-self:flex-start}
    #controls{display:flex;gap:8px;margin:12px 0 6px;flex-wrap:wrap}
    #textRow{display:flex;gap:8px;margin:10px 0 0}
    #textInput{flex:1;padding:10px 12px;border-radius:10px;border:1px solid #334155;background:#0b0e14;color:#e5e7eb}
    #ttsInstructions{width:100%;min-height:70px;padding:8px 10px;border-radius:8px;border:1px solid #334155;background:#0b0e14;color:#e5e7eb;resize:vertical}
    button{padding:10px 14px;border-radius:10px;border:0;background:#2563eb;color:white;font-weight:600;cursor:pointer}
    button.secondary{background:#334155}
    button:disabled{opacity:.5;cursor:not-allowed}
    #hint{font-size:12px;opacity:.7}
  </style>
</head>
<body>
  <div id="app">
    <h1>üéôÔ∏è Voice Chat</h1>
    <div id="status"><span id="indicator">‚ö™</span><span id="status-text">Idle</span></div>
    <div id="chat"></div>
    <div id="textRow">
      <input id="textInput" type="text" placeholder="Type a message‚Ä¶">
      <button id="sendBtn" class="secondary">Send</button>
    </div>
    <div id="controls">
      <button id="startBtn">Start Conversation</button>
      <button id="stopBtn" class="secondary" disabled>Stop Conversation</button>
      <button id="muteBtn" class="secondary">Mute Mic</button>
      <button id="unlockBtn" class="secondary" style="display:none">Unlock Audio</button>
      <button id="speechToggle" class="secondary">Speech: On</button>
      <button id="configBtn" class="secondary">Config</button>
    </div>
    <audio id="replyAudio" controls style="display:none;width:100%;margin:6px 0 0"></audio>
    <div id="hint">Mic permission required. Bridge server handles STT/LLM/TTS. <span id="build"></span></div>
  </div>

  <dialog id="configDialog">
    <form method="dialog" id="configForm" style="display:flex;flex-direction:column;gap:10px;min-width:320px">
      <h3 style="margin:0">Config</h3>
      <label>Session Key<input id="sessionKey" type="text" placeholder="voice-chat:main" style="width:100%"></label>
      <label>TTS Voice<input id="voice" type="text" placeholder="cedar" style="width:100%"></label>
      <label>TTS Instructions<textarea id="ttsInstructions" placeholder="e.g., Speak warmly, calm pace, slight smile."></textarea></label>
      <div style="display:flex;gap:8px;justify-content:flex-end;margin-top:4px">
        <button id="cancelConfig" type="button" class="secondary">Cancel</button>
        <button id="saveConfig" type="submit">Save</button>
      </div>
    </form>
  </dialog>

  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.22.0/dist/ort.wasm.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.29/dist/bundle.min.js"></script>
  <script>
    (() => {
      const BUILD = '2026-02-03-1208';
      const $ = id => document.getElementById(id),
        statusText = $('status-text'),
        indicator = $('indicator'),
        chat = $('chat'),
        textInput = $('textInput'),
        sendBtn = $('sendBtn'),
        startBtn = $('startBtn'),
        stopBtn = $('stopBtn'),
        muteBtn = $('muteBtn'),
        unlockBtn = $('unlockBtn'),
        speechToggle = $('speechToggle'),
        replyAudioEl = $('replyAudio'),
        configBtn = $('configBtn'),
        configDialog = $('configDialog'),
        configForm = $('configForm'),
        cancelConfig = $('cancelConfig'),
        ttsInstructions = $('ttsInstructions');

      const buildEl = $('build');
      if (buildEl) buildEl.textContent = `build ${BUILD}`;

      const DEFAULT_TTS_INSTRUCTIONS = "Voice Affect: Calm, composed, and reassuring; project quiet authority and confidence.\n\nTone: Sincere, empathetic, and gently authoritative‚Äîexpress genuine apology while conveying competence.\n\nPacing: Steady and moderate; unhurried enough to communicate care, yet efficient enough to demonstrate professionalism.\n\nEmotion: Genuine empathy and understanding; speak with warmth, especially during apologies (\"I'm very sorry for any disruption...\").\n\nPronunciation: Clear and precise, emphasizing key reassurances (\"smoothly,\" \"quickly,\" \"promptly\") to reinforce confidence.\n\nPauses: Brief pauses after offering assistance or requesting details, highlighting willingness to listen and support.";
      const config = { sessionKey:'voice-chat:main', voice:'cedar', instructions: DEFAULT_TTS_INSTRUCTIONS };
      let status='stopped', running=false, busy=false, vadInstance=null, currentAssistantEl=null, currentAudio=null, lastReplyText='', audioCtx=null, audioUnlocked=false, currentSource=null, isSpeaking=false, speechEnabled=true, isRecording=false, isMuted=false;
      const audioQueue = [];
      let pendingReplyText = '';
      let skippedReplyCount = 0;
      const statusMap = { listening:['üü¢','Listening...'], recording:['üî¥','Recording...'], processing:['üü°','Processing...'], thinking:['üü£','Thinking...'], speaking:['üîµ','Speaking...'], error:['‚ö´','Error'], stopped:['‚èπÔ∏è','Stopped'] };

      const setStatus = (state, detail) => {
        status = state;
        let s = state;
        if (isMuted && !['speaking','error','stopped'].includes(state)) s = 'stopped';
        const [icon, text] = statusMap[s] || ['‚ö™', s];
        indicator.textContent = icon;
        statusText.textContent = detail || (isMuted && !['speaking','error','stopped'].includes(state) ? 'Muted' : text);
      };

      const tryPlayTts = async () => {
        if (!speechEnabled || !audioUnlocked) return;
        if (isSpeaking || isRecording || busy) return;
        if (!pendingReplyText) return;
        const catchup = skippedReplyCount > 0
          ? 'Quick catch-up: I sent earlier details in chat. Latest reply: '
          : '';
        const toSpeak = catchup + pendingReplyText;
        pendingReplyText = '';
        skippedReplyCount = 0;
        await speak(toSpeak);
      };
      const addMessage = (role, text) => {
        const div = document.createElement('div');
        div.className = `msg ${role}`;
        div.textContent = `${role === 'user' ? 'You' : 'Clawd'}: ${text}`;
        chat.appendChild(div);
        chat.scrollTop = chat.scrollHeight;
        return div;
      };
      const updateAssistant = (text) => {
        if (!currentAssistantEl) currentAssistantEl = addMessage('assistant', '');
        currentAssistantEl.textContent = `Clawd: ${text}`;
        chat.scrollTop = chat.scrollHeight;
      };

      const loadConfig = () => {
        const saved = localStorage.getItem('voice-chat-config');
        if (saved) {
          try {
            const parsed = JSON.parse(saved);
            Object.assign(config, parsed);
            if (parsed?.voice === 'nova') config.voice = 'cedar';
          } catch {}
        }
        if (!config.instructions) config.instructions = DEFAULT_TTS_INSTRUCTIONS;
        if (!config.voice) config.voice = 'cedar';
      };
      const saveConfig = () => localStorage.setItem('voice-chat-config', JSON.stringify(config));
      const loadSpeechPref = () => {
        const saved = localStorage.getItem('voice-chat-speech');
        if (saved === 'off') speechEnabled = false;
        if (speechToggle) speechToggle.textContent = speechEnabled ? 'Speech: On' : 'Speech: Off';
      };
      const saveSpeechPref = () => localStorage.setItem('voice-chat-speech', speechEnabled ? 'on' : 'off');
      const fillConfigForm = () => {
        $('sessionKey').value = config.sessionKey || '';
        $('voice').value = config.voice || '';
        if (ttsInstructions) ttsInstructions.value = config.instructions || '';
      };
      const applyFormToConfig = () => {
        config.sessionKey = $('sessionKey').value.trim() || 'voice-chat:main';
        config.voice = $('voice').value.trim() || 'cedar';
        config.instructions = (ttsInstructions?.value || '').trim();
      };
      const ensureConfig = async (force=false) => {
        loadConfig();
        if (force || !config.sessionKey) {
          fillConfigForm();
          configDialog.showModal();
          return false;
        }
        return true;
      };

      const sendText = async (text) => {
        const msg = text?.trim();
        if (!msg) return;
        const ok = await ensureConfig();
        if (!ok) return;
        addMessage('user', msg);
        if (textInput) textInput.value = '';
        try {
          setStatus('thinking');
          const reply = await sendMessage(msg);
          if (reply) {
            updateAssistant(reply);
            lastReplyText = reply;
            if (speechEnabled) {
              if (audioUnlocked) {
                if (pendingReplyText) skippedReplyCount += 1;
                pendingReplyText = reply;
                await tryPlayTts();
              } else {
                setStatus('listening', 'Tap Start to enable audio');
              }
            } else if (running) {
              setStatus('listening');
            } else {
              setStatus('stopped');
            }
          }
          currentAssistantEl = null;
        } catch (error) {
          console.error('Text send error:', error);
          setStatus('error', error?.message || String(error) || 'Text send error');
        }
      };

      const float32ToWav = (samples, sampleRate=16000) => {
        const buffer = new ArrayBuffer(44 + samples.length * 2);
        const view = new DataView(buffer);
        const writeStr = (offset, str) => { for (let i=0; i<str.length; i++) view.setUint8(offset+i, str.charCodeAt(i)); };
        writeStr(0,'RIFF'); view.setUint32(4,36+samples.length*2,true); writeStr(8,'WAVE'); writeStr(12,'fmt ');
        view.setUint32(16,16,true); view.setUint16(20,1,true); view.setUint16(22,1,true); view.setUint32(24,sampleRate,true);
        view.setUint32(28,sampleRate*2,true); view.setUint16(32,2,true); view.setUint16(34,16,true); writeStr(36,'data');
        view.setUint32(40,samples.length*2,true);
        for (let i=0; i<samples.length; i++) { const s=Math.max(-1,Math.min(1,samples[i])); view.setInt16(44+i*2, s<0?s*0x8000:s*0x7fff, true); }
        return new Blob([buffer], {type:'audio/wav'});
      };

      const blobToBase64 = async (blob) => {
        const buf = await blob.arrayBuffer();
        const bytes = new Uint8Array(buf);
        let binary = '';
        for (let i=0; i<bytes.length; i++) binary += String.fromCharCode(bytes[i]);
        return btoa(binary);
      };

      const transcribe = async (wavBlob) => {
        const audioBase64 = await blobToBase64(wavBlob);
        const response = await fetch('/api/transcribe', {
          method:'POST',
          headers:{'Content-Type':'application/json'},
          body: JSON.stringify({ audioBase64, mimeType:'audio/wav' })
        });
        if (!response.ok) {
          const text = await response.text().catch(() => '');
          throw new Error(`Transcribe error ${response.status}: ${text || 'no body'}`);
        }
        let data;
        try {
          data = await response.json();
        } catch (err) {
          throw new Error(`Transcribe parse error: ${String(err)}`);
        }
        return data.text || '';
      };

      const sendMessage = async (text) => {
        const response = await fetch('/api/chat', {
          method:'POST',
          headers:{'Content-Type':'application/json'},
          body: JSON.stringify({ text, sessionKey: config.sessionKey, mode: 'voice' })
        });
        if (!response.ok) {
          const body = await response.text().catch(() => '');
          throw new Error(`Chat error ${response.status}: ${body || 'no body'}`);
        }
        let data;
        try {
          data = await response.json();
        } catch (err) {
          throw new Error(`Chat parse error: ${String(err)}`);
        }
        return data.text || '';
      };

      const ensureAudioContext = async () => {
        if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        if (audioCtx.state === 'suspended') await audioCtx.resume();
        window.audioCtx = audioCtx;
      };
      const unlockAudio = async () => {
        await ensureAudioContext();
        const buffer = audioCtx.createBuffer(1, 1, 22050);
        const source = audioCtx.createBufferSource();
        source.buffer = buffer;
        source.connect(audioCtx.destination);
        source.start(0);
        audioUnlocked = true;
      };

      const padBuffer = (buffer, preMs=80, postMs=120) => {
        const pre = Math.floor(buffer.sampleRate * (preMs/1000));
        const post = Math.floor(buffer.sampleRate * (postMs/1000));
        const padded = audioCtx.createBuffer(buffer.numberOfChannels, buffer.length + pre + post, buffer.sampleRate);
        for (let ch=0; ch<buffer.numberOfChannels; ch++) {
          padded.getChannelData(ch).set(buffer.getChannelData(ch), pre);
        }
        return padded;
      };

      const speak = async (text) => {
        if (!text) return;
        setStatus('speaking');
        try {
          await ensureAudioContext();
          const payload = { text, voice: config.voice };
          if (config.instructions) payload.instructions = config.instructions;
          const response = await fetch('/api/tts', {
            method:'POST',
            headers:{'Content-Type':'application/json'},
            body: JSON.stringify(payload)
          });
          if (!response.ok) {
            const body = await response.text().catch(() => '');
            throw new Error(`TTS error ${response.status}: ${body || 'no body'}`);
          }
          const arrayBuffer = await response.arrayBuffer();
          const buffer = await audioCtx.decodeAudioData(arrayBuffer);
          const padded = padBuffer(buffer);
          if (currentSource) { try { currentSource.stop(); } catch {} }
          const source = audioCtx.createBufferSource();
          currentSource = source;
          isSpeaking = true;
          source.buffer = padded;
          source.connect(audioCtx.destination);
          source.onended = () => {
            isSpeaking = false;
            currentSource = null;
            if (running) setStatus('listening');
            tryPlayTts();
          };
          source.start(0);
        } catch (err) {
          console.error('TTS playback failed', err);
          isSpeaking = false;
          currentSource = null;
          setStatus('error', `Audio error: ${err?.message || String(err)}`);
          tryPlayTts();
        }
      };

      const processAudio = async (audioSamples) => {
        try {
          const wavBlob = float32ToWav(audioSamples);
          const transcript = (await transcribe(wavBlob)).trim();
          if (!transcript) return;
          addMessage('user', transcript);
          setStatus('thinking');
          const reply = await sendMessage(transcript);
          if (reply) {
            updateAssistant(reply);
            lastReplyText = reply;
            if (speechEnabled) {
              if (audioUnlocked) {
                if (pendingReplyText) skippedReplyCount += 1;
                pendingReplyText = reply;
                await tryPlayTts();
              } else {
                setStatus('listening', 'Tap Start to enable audio');
              }
            } else if (running) {
              setStatus('listening');
            } else {
              setStatus('stopped');
            }
          }
          currentAssistantEl = null;
        } catch (error) {
          console.error('Processing error:', error);
          setStatus('error', error?.message || String(error) || 'Processing error');
        }
      };

      const processNextAudio = async () => {
        if (busy || audioQueue.length === 0) return;
        busy = true;
        setStatus('processing');
        const next = audioQueue.shift();
        await processAudio(next);
        busy = false;
        if (running && status === 'processing') setStatus('listening');
        if (audioQueue.length > 0) processNextAudio();
        tryPlayTts();
      };

      const startVAD = async () => {
        vadInstance = await vad.MicVAD.new({
          positiveSpeechThreshold: 0.7,
          minSpeechFrames: 6,
          preSpeechPadFrames: 2,
          onSpeechStart: () => {
            if (currentAudio) { currentAudio.pause(); currentAudio = null; }
            if (isSpeaking && currentSource) { try { currentSource.stop(); } catch {} isSpeaking = false; currentSource = null; }
            isRecording = true;
            setStatus('recording');
          },
          onSpeechEnd: async (audio) => {
            if (!running) return;
            isRecording = false;
            audioQueue.push(audio);
            processNextAudio();
          },
          onnxWASMBasePath:'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.22.0/dist/',
          baseAssetPath:'https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.29/dist/'
        });
        vadInstance.start();
      };

      const start = async () => {
        if (running) return;
        const ok = await ensureConfig();
        if (!ok) return;
        running = true; startBtn.disabled = true; stopBtn.disabled = false;
        try {
          await unlockAudio();
        } catch (err) {
          console.error('Audio unlock failed', err);
          if (unlockBtn) unlockBtn.style.display = 'inline-block';
        }
        await startVAD();
        if (isMuted && vadInstance) vadInstance.pause();
        setStatus(isMuted ? 'stopped' : 'listening', isMuted ? 'Muted' : undefined);
      };
      const stop = () => {
        running = false;
        if (vadInstance) { vadInstance.pause(); vadInstance = null; }
        if (currentAudio) { currentAudio.pause(); currentAudio = null; }
        audioQueue.length = 0;
        pendingReplyText = '';
        skippedReplyCount = 0;
        isRecording = false;
        setStatus('stopped'); startBtn.disabled = false; stopBtn.disabled = true;
      };

      startBtn.addEventListener('click', start);
      stopBtn.addEventListener('click', stop);
      if (sendBtn && textInput) {
        sendBtn.addEventListener('click', async () => {
          try { await ensureAudioContext(); audioUnlocked = true; } catch {}
          await sendText(textInput.value);
        });
        textInput.addEventListener('keydown', async (e) => {
          if (e.key === 'Enter') {
            e.preventDefault();
            try { await ensureAudioContext(); audioUnlocked = true; } catch {}
            await sendText(textInput.value);
          }
        });
      }
      if (muteBtn) {
        muteBtn.addEventListener('click', async () => {
          isMuted = !isMuted;
          muteBtn.textContent = isMuted ? 'Unmute Mic' : 'Mute Mic';
          if (isMuted) {
            if (vadInstance) vadInstance.pause();
            setStatus('stopped', 'Muted');
          } else {
            if (running && vadInstance) vadInstance.start();
            if (running) {
              if (isSpeaking) setStatus('speaking');
              else if (busy) setStatus('processing');
              else if (isRecording) setStatus('recording');
              else setStatus('listening');
            } else {
              setStatus('stopped');
            }
          }
        });
      }
      if (unlockBtn) {
        unlockBtn.addEventListener('click', async () => {
          try {
            await unlockAudio();
            unlockBtn.style.display = 'none';
            setStatus(running ? 'listening' : 'stopped', 'Audio unlocked');
            await tryPlayTts();
          } catch (err) {
            setStatus('error', `Unlock failed: ${err?.message || String(err)}`);
          }
        });
      }
      if (speechToggle) {
        speechToggle.addEventListener('click', async () => {
          speechEnabled = !speechEnabled;
          speechToggle.textContent = speechEnabled ? 'Speech: On' : 'Speech: Off';
          saveSpeechPref();
          if (speechEnabled) {
            try { await ensureAudioContext(); audioUnlocked = true; } catch {}
            await tryPlayTts();
          }
        });
      }
      configBtn.addEventListener('click', () => { loadConfig(); fillConfigForm(); configDialog.showModal(); });
      cancelConfig.addEventListener('click', () => configDialog.close());
      configForm.addEventListener('submit', (e) => {
        e.preventDefault();
        applyFormToConfig();
        saveConfig();
        configDialog.close();
      });

      loadConfig();
      loadSpeechPref();
      setStatus('stopped');
    })();
  </script>
</body>
</html>
